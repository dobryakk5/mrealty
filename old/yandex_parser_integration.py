#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä –æ–±—ä—è–≤–ª–µ–Ω–∏–π Yandex Realty –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å listings_processor

–§—É–Ω–∫—Ü–∏–∏:
- –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è Yandex Realty
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ë–î –∏ Excel
"""

import os
import time
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from bs4 import BeautifulSoup

class YandexCardParser:
    """–ü–∞—Ä—Å–µ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π Yandex Realty –¥–ª—è listings_processor"""
    
    def __init__(self):
        self.driver = None
        self.timeout = 10
        self.request_delay = 2.0
        
    def setup_selenium(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç Chrome WebDriver"""
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless=new')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_argument('--disable-features=VizDisplayCompositor')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.6904.127 Safari/537.36')
            
            prefs = {
                "profile.managed_default_content_settings.images": 2,
                "profile.default_content_setting_values.notifications": 2,
                "profile.default_content_settings.popups": 0
            }
            chrome_options.add_experimental_option("prefs", prefs)
            
            # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ Chrome binary
            if os.path.exists("/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"):
                chrome_options.binary_location = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
            else:
                chrome_options.binary_location = "/opt/google/chrome/google-chrome"
            
            print("üîß –°–æ–∑–¥–∞–µ–º –±—Ä–∞—É–∑–µ—Ä...")
            self.driver = webdriver.Chrome(options=chrome_options)

            # –ê–Ω—Ç–∏–¥–µ—Ç–µ–∫—Ç —Å–∫—Ä–∏–ø—Ç—ã –∫–∞–∫ –≤ Avito –ø–∞—Ä—Å–µ—Ä–µ
            self.driver.execute_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
                Object.defineProperty(navigator, 'languages', {get: () => ['ru-RU', 'ru', 'en-US', 'en']});
                window.chrome = {runtime: {}};
            """)
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ Chrome: {e}")
            return False

    def _clean(self, s):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"""
        if s is None:
            return None
        return re.sub(r'\s+', ' ', s).strip()

    def parse_card(self, url):
        """–ü–∞—Ä—Å–∏—Ç –ø–æ–ª–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è Yandex Realty"""
        return self.parse_yandex_page(url)

    def extract_quick_data(self, html):
        """–ë—ã—Å—Ç—Ä–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ü–µ–Ω—É –∏ —Å—Ç–∞—Ç—É—Å –∏–∑ HTML"""
        soup = BeautifulSoup(html, 'html.parser')
        result = {}

        # –¶–µ–Ω–∞
        try:
            price_selectors = [
                # –£—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–µ–Ω–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ –∏–∑–º–µ–Ω—è—Ç—Å—è)
                '[data-test-id="price-value"]',          # data-test-id –æ–±—ã—á–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω—ã
                'span[class*="price"][class*="Price"]',  # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ —Å Price
                'span[class*="SummaryInfo"][class*="price"]',  # SummaryInfo + price
                # –¢–µ–∫—É—â–∏–µ —Ç–æ—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–æ–≥—É—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è)
                '.OfferCardSummaryInfo__price--2FD3C',
                # –û–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∫–∞–∫ fallback
                'span[class*="price"]',                   # –õ—é–±–æ–π —Å–ø–∞–Ω —Å price –≤ –∫–ª–∞—Å—Å–µ
                '.price__value',                         # –û–±—â–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä
                'h1 + span'                              # –°–ø–∞–Ω –ø–æ—Å–ª–µ h1 (—Ü–µ–Ω–∞ –æ–±—ã—á–Ω–æ –∏–¥–µ—Ç –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞)
            ]
            for selector in price_selectors:
                price_el = soup.select_one(selector)
                if price_el:
                    price_text = self._clean(price_el.get_text())
                    if price_text:
                        price_clean = price_text.replace('&nbsp;', ' ').replace('\xa0', ' ')
                        price_digits = re.sub(r'[^\d]', '', price_clean)
                        if price_digits and len(price_digits) >= 6 and len(price_digits) <= 12:
                            candidate_price = int(price_digits)
                            if 100000 <= candidate_price <= 1000000000:
                                result['price'] = candidate_price
                                break
        except Exception:
            pass

        # –°—Ç–∞—Ç—É—Å - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
        try:
            result['status'] = 'active'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–∫—Ç–∏–≤–Ω–æ

            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∞—Å–Ω—É—é –º–µ—Ç–∫—É "—Å–Ω—è—Ç–æ –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª–æ" —Ä—è–¥–æ–º —Å —Ü–µ–Ω–æ–π
            status_tag_selectors = [
                # –£—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–µ–Ω–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ –∏–∑–º–µ–Ω—è—Ç—Å—è)
                '[data-test="Badge"]',                                      # data-test —Å—Ç–∞–±–∏–ª–µ–Ω
                'div[class*="red"][class*="Badge"]',                        # –ö—Ä–∞—Å–Ω—ã–π –±–µ–π–¥–∂
                'div[class*="Badge"][class*="view_red"]',                   # –ë–µ–π–¥–∂ —Å –∫—Ä–∞—Å–Ω—ã–º –≤–∏–¥–æ–º
                '*[class*="badgeText"]',                                    # –õ—é–±–æ–π —Ç–µ–∫—Å—Ç –±–µ–π–¥–∂–∞
                '*[class*="tags"] *[class*="Badge"]',                       # –ë–µ–π–¥–∂ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ —Ç–µ–≥–æ–≤
                # –¢–µ–∫—É—â–∏–µ —Ç–æ—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–æ–≥—É—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è)
                '.OfferCardSummary__tags--QypeB .Badge__badgeText--GkeO3',  # –¢–æ—á–Ω—ã–π –ø—É—Ç—å –∫ —Ç–µ–∫—Å—Ç—É –±–µ–π–¥–∂–∞
                '.Badge__view_red--oJExh .Badge__badgeText--GkeO3',         # –ö—Ä–∞—Å–Ω—ã–π –±–µ–π–¥–∂ —Å —Ç–µ–∫—Å—Ç–æ–º
                '.Badge__badgeText--GkeO3',                                 # –õ—é–±–æ–π —Ç–µ–∫—Å—Ç –±–µ–π–¥–∂–∞
                '.OfferCardSummary__tags--QypeB',                           # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Ç–µ–≥–æ–≤
                # –û–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∫–∞–∫ fallback
                '[class*="Badge"]',
                '[class*="badge"]',
                '[class*="Tag"]',
                '[class*="tag"]'
            ]

            for selector in status_tag_selectors:
                status_elements = soup.select(selector)
                for element in status_elements:
                    status_text = self._clean(element.get_text().lower())
                    if status_text and any(marker in status_text for marker in ['—Å–Ω—è—Ç–æ', '—É—Å—Ç–∞—Ä–µ–ª–æ', '–Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω–æ']):
                        result['status'] = 'inactive'
                        print(f"üî¥ –ù–∞–π–¥–µ–Ω–∞ –º–µ—Ç–∫–∞ —Å—Ç–∞—Ç—É—Å–∞: '{status_text}' –≤ —Å–µ–ª–µ–∫—Ç–æ—Ä–µ: {selector}")
                        break
                if result['status'] == 'inactive':
                    break

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if result['status'] == 'active':
                page_text = soup.get_text()
                if '–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–Ω—è—Ç–æ –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª–æ' in page_text.lower():
                    result['status'] = 'inactive'
                    print("üî¥ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–Ω—è—Ç–æ –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª–æ' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")

            # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if result['status'] == 'active':
                title_tag = soup.find('title')
                if title_tag:
                    title_text = title_tag.get_text().lower()
                    if any(word in title_text for word in ['—Å–Ω—è—Ç–æ', '—É—Å—Ç–∞—Ä–µ–ª–æ', '–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ']):
                        result['status'] = 'inactive'

            # 3. –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã - –µ—Å–ª–∏ –Ω–µ—Ç —Ñ–æ—Ç–æ, –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ
            if result['status'] == 'active':
                page_html = str(soup)
                has_photos = any(indicator in page_html for indicator in [
                    'data-test-id="photo-thumbnail"',
                    'data-test-id="gallery"'
                ])
                if not has_photos and '–ø–æ—Ö–æ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è' in page_html.lower():
                    result['status'] = 'inactive'

        except Exception:
            result['status'] = 'active'

        return result

    def extract_all_data(self, html):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ HTML"""
        soup = BeautifulSoup(html, 'html.parser')
        result = {}
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ - –∏–∑–≤–ª–µ–∫–∞–µ–º area –∏ rooms
        try:
            title_selectors = ['h1[data-test-id="offer-title"]', '.OfferTitle', 'h1']
            for selector in title_selectors:
                title_el = soup.select_one(selector)
                if title_el:
                    title_text = self._clean(title_el.get_text())
                    if title_text:
                        area_match = re.search(r'(\d+(?:[.,]\d+)?)\s*–º¬≤', title_text)
                        if area_match:
                            result['area_m2'] = float(area_match.group(1).replace(',', '.'))
                        
                        if '—Å—Ç—É–¥–∏—è' in title_text.lower():
                            result['rooms'] = 0
                        else:
                            rooms_match = re.search(r'(\d+)[\s-]*–∫–æ–º–Ω', title_text, re.IGNORECASE)
                            if rooms_match:
                                result['rooms'] = int(rooms_match.group(1))
                        break
        except Exception:
            pass

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ OfferCard__techFeatures
        try:
            tech_features = soup.select_one('.OfferCard__techFeatures--3Zoaa')
            if tech_features:
                highlights = tech_features.select('.OfferCardHighlight__container--2gZn2')
                for highlight in highlights:
                    try:
                        value_el = highlight.select_one('.OfferCardHighlight__value--HMVgP')
                        label_el = highlight.select_one('.OfferCardHighlight__label--2uMCy')
                        
                        if value_el and label_el:
                            value_text = self._clean(value_el.get_text())
                            label_text = self._clean(label_el.get_text()).lower()
                            
                            if '–æ–±—â–∞—è' in label_text and value_text:
                                area_match = re.search(r'(\d+(?:[.,]\d+)?)\s*–º¬≤', value_text)
                                if area_match:
                                    result['area_m2'] = float(area_match.group(1).replace(',', '.'))
                            
                            elif '–∂–∏–ª–∞—è' in label_text and value_text:
                                area_match = re.search(r'(\d+(?:[.,]\d+)?)\s*–º¬≤', value_text)
                                if area_match:
                                    result['living_area'] = float(area_match.group(1).replace(',', '.'))
                            
                            elif '–∫—É—Ö–Ω—è' in label_text and value_text:
                                area_match = re.search(r'(\d+(?:[.,]\d+)?)\s*–º¬≤', value_text)
                                if area_match:
                                    result['kitchen_area'] = float(area_match.group(1).replace(',', '.'))
                            
                            elif '–≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏' in label_text and value_text:
                                year_match = re.search(r'(\d{4})', value_text)
                                if year_match:
                                    year = int(year_match.group(1))
                                    if 1800 <= year <= 2030:
                                        result['year_built'] = year
                            
                            elif '—ç—Ç–∞–∂' in label_text and value_text:
                                floor_match = re.search(r'(\d+)\s*—ç—Ç–∞–∂', value_text)
                                if floor_match:
                                    result['floor'] = int(floor_match.group(1))
                            
                            elif '–∏–∑' in label_text and value_text:
                                total_floors_match = re.search(r'(\d+)', value_text)
                                if total_floors_match:
                                    result['floor_total'] = int(total_floors_match.group(1))
                    
                    except Exception:
                        continue
        except Exception:
            pass

        # –¶–µ–Ω–∞
        try:
            price_selectors = [
                # –£—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–µ–Ω–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ –∏–∑–º–µ–Ω—è—Ç—Å—è)
                '[data-test-id="price-value"]',          # data-test-id –æ–±—ã—á–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω—ã
                'span[class*="price"][class*="Price"]',  # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ —Å Price
                'span[class*="SummaryInfo"][class*="price"]',  # SummaryInfo + price
                # –¢–µ–∫—É—â–∏–µ —Ç–æ—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–æ–≥—É—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è)
                '.OfferCardSummaryInfo__price--2FD3C',
                # –û–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∫–∞–∫ fallback
                'span[class*="price"]',                   # –õ—é–±–æ–π —Å–ø–∞–Ω —Å price –≤ –∫–ª–∞—Å—Å–µ
                '.price__value',                         # –û–±—â–∏–π —Å–µ–ª–µ–∫—Ç–æ—Ä
                'h1 + span'                              # –°–ø–∞–Ω –ø–æ—Å–ª–µ h1 (—Ü–µ–Ω–∞ –æ–±—ã—á–Ω–æ –∏–¥–µ—Ç –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞)
            ]
            for selector in price_selectors:
                price_el = soup.select_one(selector)
                if price_el:
                    price_text = self._clean(price_el.get_text())
                    if price_text:
                        price_clean = price_text.replace('&nbsp;', ' ').replace('\xa0', ' ')
                        price_digits = re.sub(r'[^\d]', '', price_clean)
                        if price_digits and len(price_digits) >= 6 and len(price_digits) <= 12:
                            candidate_price = int(price_digits)
                            if 100000 <= candidate_price <= 1000000000:
                                result['price'] = candidate_price
                                break
        except Exception:
            pass

        # –≠—Ç–∞–∂
        try:
            page_text = soup.get_text()
            floor_match = re.search(r'(\d+)\s*/\s*(\d+)', page_text)
            if floor_match:
                result['floor'] = int(floor_match.group(1))
                result['floor_total'] = int(floor_match.group(2))
        except Exception:
            pass

        # –ê–¥—Ä–µ—Å
        try:
            address_selectors = ['.CardLocation__addressItem--1JYpZ', '[data-test-id="offer-location"]']
            for selector in address_selectors:
                address_el = soup.select_one(selector)
                if address_el:
                    address_text = self._clean(address_el.get_text())
                    if address_text and len(address_text) > 5:
                        result['address'] = address_text
                        break
        except Exception:
            pass

        # –ú–µ—Ç—Ä–æ - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∫–∞–∫ –≤ Avito
        try:
            metro_selectors = [
                '[data-test-id="metro-station"]', 
                '.MetroStation',
                '.OfferCardMetro',
                '.CardLocation__metro',
                '.Metro__station'
            ]
            
            for selector in metro_selectors:
                metro_blocks = soup.select(selector)
                for metro_block in metro_blocks:
                    metro_text = self._clean(metro_block.get_text())
                    if metro_text and result.get('metro') is None:
                        # –û—á–∏—â–∞–µ–º –æ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ "–º." –∏ "–º–µ—Ç—Ä–æ"
                        metro_clean = re.sub(r'(^|\s+)(–º\.|^m\.|^–º–µ—Ç—Ä–æ)', '', metro_text, flags=re.IGNORECASE).strip()
                        
                        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –¥–æ –º–µ—Ç—Ä–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
                        time_patterns = [
                            r'(\d+)\s*–º–∏–Ω',  # "10 –º–∏–Ω"
                            r'(\d+)\s*min',   # "10 min"
                            r'(\d+)\s*–º',     # "10 –º"
                            r'(\d+)-\d+\s*–º–∏–Ω',  # "5-10 –º–∏–Ω" - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ
                            r'(\d+)‚Äì\d+\s*–º–∏–Ω',  # "em dash" variant
                        ]
                        
                        walk_minutes = None
                        for time_pattern in time_patterns:
                            time_match = re.search(time_pattern, metro_text)
                            if time_match:
                                walk_minutes = int(time_match.group(1))
                                break
                        
                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º—è –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–∞–Ω—Ü–∏–∏
                        if walk_minutes:
                            # –£–¥–∞–ª—è–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
                            for time_pattern in time_patterns:
                                metro_clean = re.sub(time_pattern, '', metro_clean, flags=re.IGNORECASE).strip()
                            
                            result['walk_minutes'] = walk_minutes
                        
                        # –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏
                        metro_clean = re.sub(r'[,\-\s\.]+$', '', metro_clean).strip()
                        
                        if metro_clean and len(metro_clean) > 2:
                            result['metro'] = metro_clean
                            break
                if result.get('metro'):
                    break
                    
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –º–µ—Ç—Ä–æ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∫–∞–∫ –≤ Avito)
            if not result.get('metro'):
                try:
                    page_text = soup.get_text()
                    # –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤–∏–¥–∞ "–ú–µ—Ç—Ä–æ 10 –º–∏–Ω –ø–µ—à–∫–æ–º" –∏–ª–∏ "–£–ª–∏—Ü–∞ 1905 –≥–æ–¥–∞, 10 –º–∏–Ω"
                    metro_patterns = [
                        r'–ú–µ—Ç—Ä–æ\s+(\d+)\s*–º–∏–Ω\s*–ø–µ—à–∫–æ–º',  # "–ú–µ—Ç—Ä–æ 10 –º–∏–Ω –ø–µ—à–∫–æ–º"
                        r'([A-–Ø–∞-—è\s\d\-‚Ññ—ë–Å]+?)\s*,\s*(\d+)\s*–º–∏–Ω',  # "–£–ª–∏—Ü–∞ 1905 –≥–æ–¥–∞, 10 –º–∏–Ω"
                        r'–º\s*\.\s*([A-–Ø–∞-—è\s\d\-‚Ññ—ë–Å]+?)\s*,\s*(\d+)\s*–º–∏–Ω',  # "–º. –£–ª–∏—Ü–∞ 1905 –≥–æ–¥–∞, 10 –º–∏–Ω"
                    ]
                    
                    for pattern in metro_patterns:
                        metro_match = re.search(pattern, page_text, re.IGNORECASE)
                        if metro_match:
                            if len(metro_match.groups()) == 1:  # –ü–µ—Ä–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω - —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º—è
                                result['walk_minutes'] = int(metro_match.group(1))
                            else:  # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã - —Å—Ç–∞–Ω—Ü–∏—è –∏ –≤—Ä–µ–º—è
                                result['metro'] = metro_match.group(1).strip()
                                result['walk_minutes'] = int(metro_match.group(2))
                            break
                except Exception:
                    pass
                    
        except Exception:
            pass

        # –¢–∏–ø –¥–æ–º–∞ –∏ –≥–æ–¥ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≥–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ—Ö–±–ª–æ–∫–µ)
        try:
            page_text = soup.get_text()
            house_patterns = ['–∫–∏—Ä–ø–∏—á–Ω—ã–π', '–ø–∞–Ω–µ–ª—å–Ω—ã–π', '–º–æ–Ω–æ–ª–∏—Ç–Ω—ã–π']
            for pattern in house_patterns:
                if re.search(pattern, page_text, re.IGNORECASE):
                    result['house_type'] = pattern
                    break
            
            # –ò—â–µ–º –≥–æ–¥ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –Ω–µ –±—ã–ª –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º –±–ª–æ–∫–µ
            if 'year_built' not in result or result.get('year_built') is None:
                year_match = re.search(r'(19\d{2}|20\d{2})', page_text)
                if year_match:
                    year = int(year_match.group(1))
                    if 1900 <= year <= 2030:
                        result['year_built'] = year
        except Exception:
            pass

        # –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∫–≤–∞—Ä—Ç–∏—Ä—ã
        try:
            features_text = []
            features_elements = soup.select('.OfferCardFeature__text--_Hmzv')
            for text_el in features_elements:
                feature_text = self._clean(text_el.get_text())
                if feature_text and len(feature_text) > 3 and '‚ÇΩ' not in feature_text:
                    features_text.append(feature_text.lower())
            
            combined_features = ' '.join(features_text)
            
            if '–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–º–æ–Ω—Ç' in combined_features:
                result['renovation'] = '–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–º–æ–Ω—Ç'
            
            if '—Å–∞–Ω—É–∑–µ–ª —Ä–∞–∑–¥–µ–ª—å–Ω—ã–π' in combined_features:
                result['bathroom_type'] = 'separate'
            elif '—Å–∞–Ω—É–∑–µ–ª —Å–æ–≤–º–µ—â–µ–Ω–Ω—ã–π' in combined_features:
                result['bathroom_type'] = 'combined'
            
            if '–ª–æ–¥–∂–∏—è' in combined_features:
                result['balcony'] = 'loggia'
            elif '–±–∞–ª–∫–æ–Ω' in combined_features:
                result['balcony'] = 'balcony'
            
            if '–Ω–∞ —É–ª–∏—Ü—É' in combined_features:
                result['window_view'] = '–Ω–∞ —É–ª–∏—Ü—É'
        except Exception:
            pass

        # –°—Ç–∞—Ç—É—Å
        try:
            result['status'] = 'active'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–∫—Ç–∏–≤–Ω–æ

            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∞—Å–Ω—É—é –º–µ—Ç–∫—É "—Å–Ω—è—Ç–æ –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª–æ" —Ä—è–¥–æ–º —Å —Ü–µ–Ω–æ–π
            status_tag_selectors = [
                # –£—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–µ–Ω–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ –∏–∑–º–µ–Ω—è—Ç—Å—è)
                '[data-test="Badge"]',                                      # data-test —Å—Ç–∞–±–∏–ª–µ–Ω
                'div[class*="red"][class*="Badge"]',                        # –ö—Ä–∞—Å–Ω—ã–π –±–µ–π–¥–∂
                'div[class*="Badge"][class*="view_red"]',                   # –ë–µ–π–¥–∂ —Å –∫—Ä–∞—Å–Ω—ã–º –≤–∏–¥–æ–º
                '*[class*="badgeText"]',                                    # –õ—é–±–æ–π —Ç–µ–∫—Å—Ç –±–µ–π–¥–∂–∞
                '*[class*="tags"] *[class*="Badge"]',                       # –ë–µ–π–¥–∂ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ —Ç–µ–≥–æ–≤
                # –¢–µ–∫—É—â–∏–µ —Ç–æ—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã (–º–æ–≥—É—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è)
                '.OfferCardSummary__tags--QypeB .Badge__badgeText--GkeO3',  # –¢–æ—á–Ω—ã–π –ø—É—Ç—å –∫ —Ç–µ–∫—Å—Ç—É –±–µ–π–¥–∂–∞
                '.Badge__view_red--oJExh .Badge__badgeText--GkeO3',         # –ö—Ä–∞—Å–Ω—ã–π –±–µ–π–¥–∂ —Å —Ç–µ–∫—Å—Ç–æ–º
                '.Badge__badgeText--GkeO3',                                 # –õ—é–±–æ–π —Ç–µ–∫—Å—Ç –±–µ–π–¥–∂–∞
                '.OfferCardSummary__tags--QypeB',                           # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Ç–µ–≥–æ–≤
                # –û–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∫–∞–∫ fallback
                '[class*="Badge"]',
                '[class*="badge"]',
                '[class*="Tag"]',
                '[class*="tag"]'
            ]

            for selector in status_tag_selectors:
                status_elements = soup.select(selector)
                for element in status_elements:
                    status_text = self._clean(element.get_text().lower())
                    if status_text and any(marker in status_text for marker in ['—Å–Ω—è—Ç–æ', '—É—Å—Ç–∞—Ä–µ–ª–æ', '–Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω–æ']):
                        result['status'] = 'inactive'
                        print(f"üî¥ –ù–∞–π–¥–µ–Ω–∞ –º–µ—Ç–∫–∞ —Å—Ç–∞—Ç—É—Å–∞: '{status_text}' –≤ —Å–µ–ª–µ–∫—Ç–æ—Ä–µ: {selector}")
                        break
                if result['status'] == 'inactive':
                    break

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if result['status'] == 'active':
                page_text = soup.get_text()
                if '–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–Ω—è—Ç–æ –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª–æ' in page_text.lower():
                    result['status'] = 'inactive'
                    print("üî¥ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–Ω—è—Ç–æ –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–ª–æ' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")

            # 2. –ï—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –º–µ—Ç–∫–∞–º, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if result['status'] == 'active':
                page_html = str(soup)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–æ—Ç–æ –≥–∞–ª–µ—Ä–µ—è - –µ—Å–ª–∏ –Ω–µ—Ç, —Ç–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ
                photo_indicators = [
                    'data-test-id="photo-thumbnail"',
                    'data-test-id="gallery"',
                    'class="Gallery"',
                    '—Ñ–æ—Ç–æ –∫–≤–∞—Ä—Ç–∏—Ä—ã',
                    '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è'
                ]

                has_photos = any(indicator in page_html for indicator in photo_indicators)

                # –ï—Å–ª–∏ –Ω–µ—Ç —Ñ–æ—Ç–æ –ò –µ—Å—Ç—å "–ü–æ—Ö–æ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è" –≤ –Ω–∞—á–∞–ª–µ - –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ
                if not has_photos and '–ø–æ—Ö–æ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è' in page_html.lower():
                    result['status'] = 'inactive'

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                title_tag = soup.find('title')
                if title_tag:
                    title_text = title_tag.get_text().lower()
                    if any(word in title_text for word in ['—Å–Ω—è—Ç–æ', '—É—Å—Ç–∞—Ä–µ–ª–æ', '–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ']):
                        result['status'] = 'inactive'


        except Exception as e:
            result['status'] = 'active'

        # –ü—Ä–æ—Å–º–æ—Ç—Ä—ã
        try:
            header_elements = soup.select('.OfferCardSummaryHeader__text--2EMVm')
            for element in header_elements:
                header_text = self._clean(element.get_text())
                if header_text:
                    views_match = re.search(r'(\d+)\s*–ø—Ä–æ—Å–º–æ—Ç—Ä', header_text, re.IGNORECASE)
                    if views_match:
                        result['views_count'] = int(views_match.group(1))
                        break
        except Exception:
            pass

        # –ü—Ä–æ–¥–∞–≤–µ—Ü
        try:
            seller_name_el = soup.select_one('.OfferCardAuthorBadge__name--3M271')
            if seller_name_el:
                result['seller_name'] = self._clean(seller_name_el.get_text())
            
            seller_type_el = soup.select_one('.OfferCardAuthorBadge__category--3DrfS')
            if seller_type_el:
                seller_type = self._clean(seller_type_el.get_text()).lower()
                if '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ' in seller_type:
                    result['seller_type'] = 'agency'
                elif '—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫' in seller_type:
                    result['seller_type'] = 'owner'
                else:
                    result['seller_type'] = seller_type
        except Exception:
            pass

        # –û–ø–∏—Å–∞–Ω–∏–µ
        try:
            desc_el = soup.select_one('[data-test-id="offer-description"]')
            if desc_el:
                desc_text = self._clean(desc_el.get_text())
                if desc_text and len(desc_text) > 10:
                    result['description'] = desc_text
        except Exception:
            pass

        # –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        try:
            photo_elements = soup.select('[data-test-id="photo-thumbnail"]')
            if photo_elements:
                result['photos_count'] = len(photo_elements)
        except Exception:
            pass

        return result

    def parse_yandex_quick(self, url):
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Ç–æ–ª—å–∫–æ —Ü–µ–Ω—ã –∏ —Å—Ç–∞—Ç—É—Å–∞ Yandex Realty"""
        try:
            print(f"‚ö° –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ Yandex Realty: {url}")

            if not self.setup_selenium():
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Selenium")
                return None

            print(f"üåê –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
            self.driver.get(url)

            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ
            time.sleep(1.5)

            html = self.driver.page_source
            print("üìÑ –ü–æ–ª—É—á–µ–Ω HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã")

            print("‚ö° –ë—ã—Å—Ç—Ä–æ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É –∏ —Å—Ç–∞—Ç—É—Å...")
            result = self.extract_quick_data(html)
            result['url'] = url

            print("‚úÖ –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
            return result

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return None
        finally:
            self.cleanup()

    def parse_yandex_page(self, url):
        """–ü–∞—Ä—Å–∏—Ç –ø–æ–ª–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è Yandex Realty"""
        try:
            print(f"üîÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É Yandex Realty: {url}")
            
            if not self.setup_selenium():
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Selenium")
                return None
            
            print(f"üåê –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
            self.driver.get(url)
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
            try:
                for selector in ["[data-test-id='offer-card']", ".OfferSummary", "h1"]:
                    try:
                        WebDriverWait(self.driver, 3).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                        )
                        break
                    except TimeoutException:
                        continue
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            
            time.sleep(self.request_delay)
            
            html = self.driver.page_source
            print("üìÑ –ü–æ–ª—É—á–µ–Ω HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
            
            print("üîç –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ...")
            result = self.extract_all_data(html)
            result['url'] = url
            
            print("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            return None
        finally:
            self.cleanup()

    def cleanup(self):
        """–û—á–∏—â–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã"""
        try:
            if self.driver:
                self.driver.quit()
                self.driver = None
        except Exception:
            pass

    def prepare_quick_data_for_db(self, parsed_data):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –±—ã—Å—Ç—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ü–µ–Ω–∞ + —Å—Ç–∞—Ç—É—Å) –¥–ª—è –ë–î"""
        if not parsed_data:
            return None

        db_data = {
            'url': parsed_data.get('url'),
            'price': parsed_data.get('price'),
            'status': parsed_data.get('status'),
            'source': 'yandex'
        }

        return db_data

    def prepare_data_for_db(self, parsed_data):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ë–î –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å listings_processor"""
        if not parsed_data:
            return None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º metro_time –≤ —Ñ–æ—Ä–º–∞—Ç–µ Avito: "–º–∏–Ω—É—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏–µ_—Å—Ç–∞–Ω—Ü–∏–∏"
        metro_time_formatted = None
        metro_station = parsed_data.get('metro')
        walk_minutes = parsed_data.get('walk_minutes')
        
        if metro_station and walk_minutes:
            # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            clean_station = re.sub(r'[,\-\s\.]+$', '', metro_station).strip()
            metro_time_formatted = f"{walk_minutes} {clean_station}"
        elif metro_station:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–∞–Ω—Ü–∏—è, –Ω–æ –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ - —Å—Ç–∞–≤–∏–º 0
            clean_station = re.sub(r'[,\-\s\.]+$', '', metro_station).strip()
            metro_time_formatted = f"0 {clean_station}"
        
        # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç –ë–î
        db_data = {
            'url': parsed_data.get('url'),
            'price': parsed_data.get('price'),
            'rooms': parsed_data.get('rooms'),
            'area_total': parsed_data.get('area_m2'),
            'living_area': parsed_data.get('living_area'),
            'kitchen_area': parsed_data.get('kitchen_area'),
            'floor': parsed_data.get('floor'),
            'floor_total': parsed_data.get('floor_total'),
            'address': parsed_data.get('address'),
            'metro_station': metro_station,  # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            'metro_time': metro_time_formatted,  # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–∞–∫ –≤ Avito
            'house_type': parsed_data.get('house_type'),
            'year_built': parsed_data.get('year_built'),
            'renovation': parsed_data.get('renovation'),
            'bathroom': parsed_data.get('bathroom_type'),
            'balcony': parsed_data.get('balcony'),
            'view': parsed_data.get('window_view'),
            'status': parsed_data.get('status'),
            'views': parsed_data.get('views_count'),
            'seller_name': parsed_data.get('seller_name'),
            'seller_type': parsed_data.get('seller_type'),
            'description': parsed_data.get('description'),
            'photos_count': parsed_data.get('photos_count'),
            'source': 'yandex'
        }
        
        return db_data

def test_parser():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä—Å–µ—Ä"""
    parser = YandexCardParser()
    test_url = "https://realty.yandex.ru/offer/4416594170111710645/"
    
    try:
        result = parser.parse_card(test_url)
        if result:
            print("\nüéâ –†–ï–ó–£–õ–¨–¢–ê–¢ –ü–ê–†–°–ò–ù–ì–ê:")
            for key, value in result.items():
                if value is not None:
                    print(f"  {key}: {value}")
        else:
            print("‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")

if __name__ == '__main__':
    test_parser()