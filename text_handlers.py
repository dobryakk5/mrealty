# text_handlers.py
from aiogram.types import Message, BufferedInputFile
from listings_processor import listings_processor, export_listings_to_excel, extract_urls
from db_handler import find_similar_ads_grouped
import io
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Font

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
def format_date(date_value):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—É –∏–∑ ISO —Ñ–æ—Ä–º–∞—Ç–∞ –≤ DD.MM.YYYY"""
    if not date_value:
        return ""
    
    try:
        # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ –≤ ISO —Ñ–æ—Ä–º–∞—Ç–µ
        if isinstance(date_value, str):
            from datetime import datetime
            # –ü–∞—Ä—Å–∏–º ISO —Ñ–æ—Ä–º–∞—Ç
            if 'T' in date_value:
                dt = datetime.fromisoformat(date_value.replace('Z', '+00:00'))
            else:
                dt = datetime.fromisoformat(date_value)
        else:
            # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ datetime –æ–±—ä–µ–∫—Ç
            dt = date_value
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ DD.MM.YYYY
        return dt.strftime("%d.%m.%Y")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã {date_value}: {e}")
        return str(date_value)

def format_boolean(bool_value):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ '–¥–∞' –∏–ª–∏ –ø—É—Å—Ç–æ"""
    if bool_value is None:
        return ""
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º
    str_value = str(bool_value).lower().strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã True
    if str_value in ['true', '1', 'yes', '–¥–∞', '–∞–∫—Ç–∏–≤–Ω–æ', 'active']:
        return "–¥–∞"
    
    # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –ø—É—Å—Ç–æ
    return ""

def extract_listing_comments(text: str, urls: list[str]) -> list[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –º–µ–∂–¥—É —Å—Å—ã–ª–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    –õ–æ–≥–∏–∫–∞:
    - –¢–µ–∫—Å—Ç –¥–æ –ø–µ—Ä–≤–æ–π —Å—Å—ã–ª–∫–∏ - —ç—Ç–æ subtitle (–æ–±—â–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π)
    - –¢–µ–∫—Å—Ç –æ—Ç –ø–µ—Ä–≤–æ–π –¥–æ –≤—Ç–æ—Ä–æ–π —Å—Å—ã–ª–∫–∏ - –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –ø–µ—Ä–≤–æ–º—É –æ–±—ä—è–≤–ª–µ–Ω–∏—é
    - –¢–µ–∫—Å—Ç –æ—Ç –≤—Ç–æ—Ä–æ–π –¥–æ —Ç—Ä–µ—Ç—å–µ–π —Å—Å—ã–ª–∫–∏ - –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫–æ –≤—Ç–æ—Ä–æ–º—É –æ–±—ä—è–≤–ª–µ–Ω–∏—é
    - –ò —Ç–∞–∫ –¥–∞–ª–µ–µ
    """
    import re
    comments = []
    
    if not urls:
        return comments
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏–∏ –≤—Å–µ—Ö —Å—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ
    url_positions = []
    for url in urls:
        pos = text.find(url)
        if pos != -1:
            url_positions.append((pos, url))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–∑–∏—Ü–∏–∏
    url_positions.sort(key=lambda x: x[0])
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    for i in range(len(url_positions)):
        current_pos, current_url = url_positions[i]
        
        if i == 0:
            # –î–ª—è –ø–µ—Ä–≤–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è - –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —Å—Å—ã–ª–∫–∏
            # –ò—â–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Å—ã–ª–∫—É –∏–ª–∏ –∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞
            if i + 1 < len(url_positions):
                next_pos = url_positions[i + 1][0]
                comment = text[current_pos + len(current_url):next_pos].strip()
            else:
                # –ï—Å–ª–∏ —ç—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å—Å—ã–ª–∫–∞, –±–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –Ω–µ—ë
                comment = text[current_pos + len(current_url):].strip()
        else:
            # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π - —Ç–µ–∫—Å—Ç –º–µ–∂–¥—É —Ç–µ–∫—É—â–µ–π –∏ —Å–ª–µ–¥—É—é—â–µ–π —Å—Å—ã–ª–∫–æ–π
            if i + 1 < len(url_positions):
                next_pos = url_positions[i + 1][0]
                comment = text[current_pos + len(current_url):next_pos].strip()
            else:
                # –î–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è - —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Å—ã–ª–∫–∏
                comment = text[current_pos + len(current_url):].strip()
        
        # –û—á–∏—â–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        comment = comment.replace("–ø–æ–¥–±–æ—Ä", "").replace("–ø–æ–¥–±–æ—Ä-", "").strip()
        # –£–±–∏—Ä–∞–µ–º —Ü–∏—Ñ—Ä—ã –≤ –Ω–∞—á–∞–ª–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ñ–æ—Ç–æ)
        comment = re.sub(r'^\d+\s*', '', comment).strip()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        comments.append(comment)
    
    # –î–æ–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –¥–æ –Ω—É–∂–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
    while len(comments) < len(urls):
        comments.append("")
    
    return comments

async def handle_text_message(message: Message):
    text = message.text.strip()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –∫–∞–±–∏–Ω–µ—Ç–∞
    if "–∫–∞–±–∏–Ω–µ—Ç" in text.lower():
        user_id = message.from_user.id
        cabinet_url = f"https://mrealty.netlify.app/link?i={user_id}"
        await message.answer(f"üè¢ –í–∞—à –ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç: {cabinet_url}")
        return

    is_selection_request = "–ø–æ–¥–±–æ—Ä" in text.lower()
    use_embedded = "–ø–æ–¥–±–æ—Ä" in text.lower() and "–ø–æ–¥–±–æ—Ä-" not in text.lower()  # "–ø–æ–¥–±–æ—Ä" = –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ, "–ø–æ–¥–±–æ—Ä-" = –æ–±—ã—á–Ω—ã–µ
    urls, url_count = extract_urls(text)
    
    # –°—Ä–∞–∑—É –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫
    if url_count == 0:
        await message.answer("üìã –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è CIAN –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n\n"
                             "üí° –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è Excel-–æ—Ç—á–µ—Ç–∞ –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫–∏.\n"
                             "üñºÔ∏è –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –Ω–∞–ø–∏—à–∏—Ç–µ '–ø–æ–¥–±–æ—Ä' + —Å—Å—ã–ª–∫–∏.\n"
                             "üîó –î–ª—è –æ–±—ã—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫: '–ø–æ–¥–±–æ—Ä-' + —Å—Å—ã–ª–∫–∏.")
        return
    
    await message.answer(f"‚úÖ –ü—Ä–∏–Ω—è—Ç–æ —Å—Å—ã–ª–æ–∫: {url_count}")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–æ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ URL –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∞–π–ª–æ–≤
    metro_info = "–º–µ—Ç—Ä–æ"
    # –£–±–∏—Ä–∞–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–π –≤—ã–∑–æ–≤ extract_listing_info - –æ–Ω –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –≤ generate_html_gallery_embedded
    if urls:
        try:
            # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç—Ä–æ –∏–∑ URL –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
            if 'tekstilshchiki' in urls[0].lower() or '—Ç–µ–∫—Å—Ç–∏–ª—å—â–∏–∫–∏' in urls[0].lower():
                metro_info = "–¢–µ–∫—Å—Ç–∏–ª—å—â–∏–∫–∏"
            elif 'begovaya' in urls[0].lower() or '–±–µ–≥–æ–≤–∞—è' in urls[0].lower():
                metro_info = "–ë–µ–≥–æ–≤–∞—è"
            # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–æ: {e}")
            metro_info = "–º–µ—Ç—Ä–æ"

    try:
        if is_selection_request:
            subtitle = None
            max_photos_per_listing = None  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
            listing_comments = []  # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º
            
            if "–ø–æ–¥–±–æ—Ä" in text.lower():
                podbor_pos = text.lower().find("–ø–æ–¥–±–æ—Ä")
                
                # –ò—â–µ–º —Ü–∏—Ñ—Ä—É –ø–µ—Ä–µ–¥ —Å–ª–æ–≤–æ–º "–ø–æ–¥–±–æ—Ä"
                text_before_podbor = text[:podbor_pos].strip()
                import re
                
                # –ò—â–µ–º —Ü–∏—Ñ—Ä—É –≤ –Ω–∞—á–∞–ª–µ —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ "–ø–æ–¥–±–æ—Ä" (–Ω–∞–ø—Ä–∏–º–µ—Ä: "3 –ø–æ–¥–±–æ—Ä")
                print(f"üîç DEBUG: –ò—â–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ñ–æ—Ç–æ –≤ —Ç–µ–∫—Å—Ç–µ: '{text_before_podbor}'")
                photo_limit_match = re.search(r'^(\d+)\s*', text_before_podbor)
                if photo_limit_match:
                    max_photos_per_listing = int(photo_limit_match.group(1))
                    print(f"üî¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ñ–æ—Ç–æ: {max_photos_per_listing} –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ (–Ω–∞–π–¥–µ–Ω–æ –≤ –Ω–∞—á–∞–ª–µ)")
                else:
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –Ω–∞—á–∞–ª–µ, –∏—â–µ–º –ª—é–±—É—é —Ü–∏—Ñ—Ä—É –ø–µ—Ä–µ–¥ "–ø–æ–¥–±–æ—Ä"
                    photo_limit_match = re.search(r'(\d+)\s*$', text_before_podbor)
                    if photo_limit_match:
                        max_photos_per_listing = int(photo_limit_match.group(1))
                        print(f"üî¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ñ–æ—Ç–æ: {max_photos_per_listing} –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ (–Ω–∞–π–¥–µ–Ω–æ –≤ –∫–æ–Ω—Ü–µ)")
                    else:
                        print(f"üîç DEBUG: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–æ—Ç–æ")
                
                text_after_podbor = text[podbor_pos + 6:].strip()
                first_url_pos = -1
                for url in urls:
                    pos = text_after_podbor.find(url)
                    if pos != -1:
                        first_url_pos = pos
                        break
                if first_url_pos != -1:
                    subtitle = text_after_podbor[:first_url_pos].strip()
                else:
                    subtitle = text_after_podbor
                if subtitle:
                    subtitle = subtitle.replace("–ø–æ–¥–±–æ—Ä", "").replace("–ø–æ–¥–±–æ—Ä-", "").strip()
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –º–µ–∂–¥—É —Å—Å—ã–ª–∫–∞–º–∏
                listing_comments = extract_listing_comments(text, urls)
                print(f"üìù –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º: {len(listing_comments)}")

            if use_embedded:
                html_content, photo_stats = await listings_processor.generate_html_gallery_embedded(urls, message.from_user.id, subtitle, remove_watermarks=True, max_photos_per_listing=max_photos_per_listing, listing_comments=listing_comments)
                filename = f"–ü–æ–¥–±–æ—Ä_{metro_info}.html"
                caption = f"üè† –ü–æ–¥–±–æ—Ä –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–æ—Ç–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
                if max_photos_per_listing:
                    await message.answer(f"üî¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –º–∞–∫—Å–∏–º—É–º {max_photos_per_listing} —Ñ–æ—Ç–æ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ")
                
                for stat in photo_stats:
                    if stat['photo_count'] > 0:
                        await message.answer(f"üì∏ {stat['photo_count']} —Ñ–æ—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –æ–±—ä—è–≤–ª–µ–Ω–∏—è {stat['listing_number']}")
                    else:
                        if 'error' in stat:
                            await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–æ—Ç–æ –∏–∑ –æ–±—ä—è–≤–ª–µ–Ω–∏—è {stat['listing_number']}: {stat['error']}")
                        else:
                            await message.answer(f"‚ö†Ô∏è –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –æ–±—ä—è–≤–ª–µ–Ω–∏–∏ {stat['listing_number']}")
            else:
                html_content = await listings_processor.generate_html_gallery(urls, message.from_user.id, subtitle, listing_comments, max_photos_per_listing)
                filename = f"–ü–æ–¥–±–æ—Ä_{metro_info}.html"
                caption = f"üè† –ü–æ–¥–±–æ—Ä –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ (–æ–±—ã—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏)"

            html_file = io.BytesIO(html_content.encode('utf-8'))
            html_file.name = filename
            input_file = BufferedInputFile(html_file.getvalue(), filename=filename)
            await message.answer_document(input_file, caption=caption)

        else:
            excel_file, request_id = await export_listings_to_excel(urls, message.from_user.id)
            input_file = BufferedInputFile(excel_file.getvalue(), filename=f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ_{metro_info}.xlsx")
            await message.answer_document(input_file, caption=f"üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏")
            
            # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π Excel —Ñ–∞–π–ª —Å –ø–æ—Ö–æ–∂–∏–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏
            try:
                similar_ads = await find_similar_ads_grouped(request_id)
                if similar_ads:
                    # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª —Å –ø–æ—Ö–æ–∂–∏–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏
                    similar_excel = io.BytesIO()
                    
                    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                    import pandas as pd
                    import json
                    similar_data = []
                    for group in similar_ads:
                        address = group['address']
                        ads = group['ads']
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ ads - —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞
                        if isinstance(ads, list):
                            ads_list = ads
                        elif isinstance(ads, str):
                            try:
                                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON —Å—Ç—Ä–æ–∫—É
                                ads_list = json.loads(ads)
                                if not isinstance(ads_list, list):
                                    print(f"‚ö†Ô∏è ads –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º: {type(ads_list)}")
                                    continue
                            except json.JSONDecodeError as e:
                                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                                continue
                        else:
                            print(f"‚ö†Ô∏è ads –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º –∏–ª–∏ —Å—Ç—Ä–æ–∫–æ–π: {type(ads)}")
                            continue
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                        for ad in ads_list:
                            if isinstance(ad, dict):
                                ad_copy = ad.copy()  # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
                                ad_copy['–ê–¥—Ä–µ—Å'] = address
                                
                                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                                if 'created' in ad_copy:
                                    ad_copy['created'] = format_date(ad_copy['created'])
                                if 'updated' in ad_copy:
                                    ad_copy['updated'] = format_date(ad_copy['updated'])
                                if 'is_active' in ad_copy:
                                    ad_copy['is_active'] = format_boolean(ad_copy['is_active'])
                                
                                similar_data.append(ad_copy)
                    
                    if similar_data:
                        # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ –∞–¥—Ä–µ—Å–∞–º
                        wb = Workbook()
                        ws = wb.active
                        ws.title = "–ü–æ—Ö–æ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"
                        
                        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                        headers = ['URL', '–¶–µ–Ω–∞', '–ö–æ–º–Ω–∞—Ç', '–°–æ–∑–¥–∞–Ω–æ', '–û–±–Ω–æ–≤–ª–µ–Ω–æ', '–ê–∫—Ç–∏–≤–Ω–æ', '–¢–∏–ø –ø—Ä–æ–¥–∞–≤—Ü–∞']
                        header_row = 1
                        
                        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∞–¥—Ä–µ—Å–∞–º
                        current_row = 1
                        for group in similar_ads:
                            address = group['address']
                            ads = group['ads']
                            
                            # –ü–∞—Ä—Å–∏–º ads –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
                            if isinstance(ads, str):
                                try:
                                    ads_list = json.loads(ads)
                                except json.JSONDecodeError:
                                    continue
                            else:
                                ads_list = ads
                            
                            if not isinstance(ads_list, list):
                                continue
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –∞–¥—Ä–µ—Å –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–∂–∏—Ä–Ω—ã–º —à—Ä–∏—Ñ—Ç–æ–º)
                            ws.cell(row=current_row, column=1, value=address)
                            ws.cell(row=current_row, column=1).font = Font(bold=True)
                            current_row += 1
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫
                            for col, header in enumerate(headers, 1):
                                ws.cell(row=current_row, column=col, value=header)
                                ws.cell(row=current_row, column=col).font = Font(bold=True)
                            current_row += 1
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è
                            for ad in ads_list:
                                if isinstance(ad, dict):
                                    ws.cell(row=current_row, column=1, value=ad.get('url', ''))
                                    ws.cell(row=current_row, column=2, value=ad.get('price', ''))
                                    ws.cell(row=current_row, column=3, value=ad.get('rooms', ''))
                                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã
                                    ws.cell(row=current_row, column=4, value=format_date(ad.get('created', '')))
                                    ws.cell(row=current_row, column=5, value=format_date(ad.get('updated', '')))
                                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                                    ws.cell(row=current_row, column=6, value=format_boolean(ad.get('is_active', '')))
                                    ws.cell(row=current_row, column=7, value=ad.get('person_type', ''))
                                    current_row += 1
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏
                            current_row += 1
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ BytesIO
                        similar_excel = io.BytesIO()
                        wb.save(similar_excel)
                        similar_excel.seek(0)
                        
                        similar_filename = f"–ø–æ—Ö–æ–∂–∏–µ_–æ–±—ä—è–≤–ª–µ–Ω–∏—è_{metro_info}.xlsx"
                        similar_input_file = BufferedInputFile(similar_excel.getvalue(), filename=similar_filename)
                        await message.answer_document(similar_input_file, caption=f"üîç –ü–æ—Ö–æ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
                        print(f"‚úÖ –°–æ–∑–¥–∞–Ω Excel —Å {len(similar_data)} –ø–æ—Ö–æ–∂–∏–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏")
                    else:
                        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Excel —Å –ø–æ—Ö–æ–∂–∏–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å –ø–æ—Ö–æ–∂–∏–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏: {e}")
                # –ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å —á–∞—Ç

    except Exception as e:
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        print(f"–û—à–∏–±–∫–∞ –≤ handle_text_message: {e}")
