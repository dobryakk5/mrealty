#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞–Ω—Ü–∏–π –º–µ—Ç—Ä–æ –∏–∑ –¶–ò–ê–ù —Å —Ç–∞–±–ª–∏—Ü–µ–π metro
–∏ –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è cian_id –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç–∞–Ω—Ü–∏–∏
"""

import asyncio
import csv
import re
import os
from typing import List, Dict, Optional, Tuple
import asyncpg
from dotenv import load_dotenv

# Load environment
load_dotenv()
DATABASE_URL = os.getenv('DATABASE_URL')

# ========== –ù–ê–°–¢–†–û–ô–ö–ò ==========
STATIONS_CSV_PATH = "stations.csv"  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ —Å—Ç–∞–Ω—Ü–∏—è–º–∏ –º–µ—Ç—Ä–æ

# ========== –£–¢–ò–õ–ò–¢–´ ==========

def normalize_station_name(name: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    if not name:
        return ""
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    name = name.lower().strip()
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    name = re.sub(r'\s+', ' ', name)
    
    # –£–±–∏—Ä–∞–µ–º —Å–∫–æ–±–∫–∏ –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ú–æ—Å–∫–≤–∞ (–≥–æ—Ä–æ–¥)")
    name = re.sub(r'\s*\([^)]*\)', '', name)
    
    # –£–±–∏—Ä–∞–µ–º "–º–µ—Ç—Ä–æ" –≤ –∫–æ–Ω—Ü–µ
    name = re.sub(r'\s+–º–µ—Ç—Ä–æ$', '', name)
    
    # –£–±–∏—Ä–∞–µ–º "—Å—Ç–∞–Ω—Ü–∏—è" –≤ –∫–æ–Ω—Ü–µ
    name = re.sub(r'\s+—Å—Ç–∞–Ω—Ü–∏—è$', '', name)
    
    return name.strip()



# ========== –†–ê–ë–û–¢–ê –° –ë–î ==========

async def create_metro_table(conn: asyncpg.Connection) -> None:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É metro –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    try:
        await conn.execute("""
        CREATE TABLE IF NOT EXISTS metro (
            id SERIAL PRIMARY KEY,
            name TEXT NOT NULL,
            line_id SMALLINT NOT NULL,
            lat DOUBLE PRECISION NOT NULL,
            lon DOUBLE PRECISION NOT NULL,
            exits SMALLINT NOT NULL,
            cian_id SMALLINT,
            UNIQUE(name, line_id)
        );
        
        CREATE INDEX IF NOT EXISTS idx_metro_name ON metro(name);
        CREATE INDEX IF NOT EXISTS idx_metro_cian_id ON metro(cian_id);
        CREATE INDEX IF NOT EXISTS idx_metro_line_id ON metro(line_id);
        """)
        print("[DB] –¢–∞–±–ª–∏—Ü–∞ metro —Å–æ–∑–¥–∞–Ω–∞/–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        print(f"[DB] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã metro: {e}")
        raise

def load_stations_from_csv(csv_path: str) -> List[Dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞–Ω—Ü–∏–∏ –∏–∑ CSV —Ñ–∞–π–ª–∞ –≤ –ø–∞–º—è—Ç—å"""
    stations = []
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    line_id = int(row['line_id']) if row['line_id'].isdigit() else None
                    station_id = int(row['station_id']) if row['station_id'].isdigit() else None
                    
                    if line_id is not None and station_id is not None:
                        stations.append({
                            'line_id': line_id,
                            'line_name': row['line_name'],
                            'station_id': station_id,
                            'station_name': row['station_name']
                        })
                except Exception as e:
                    print(f"[WARN] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–æ–∫–∏ {row}: {e}")
                    continue
        
        print(f"[CSV] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(stations)} —Å—Ç–∞–Ω—Ü–∏–π –∏–∑ CSV")
        return stations
        
    except Exception as e:
        print(f"[CSV] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞–Ω—Ü–∏–π: {e}")
        raise

async def get_metro_stations(conn: asyncpg.Connection) -> List[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ –∏–∑ –ë–î"""
    try:
        rows = await conn.fetch("""
        SELECT id, line_id, name, cian_id
        FROM metro
        ORDER BY line_id, id
        """)
        return [dict(row) for row in rows]
    except Exception as e:
        print(f"[DB] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–Ω—Ü–∏–π: {e}")
        raise

async def clear_existing_cian_ids(conn: asyncpg.Connection) -> int:
    """–û—á–∏—â–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ cian_id –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
    try:
        result = await conn.execute("UPDATE metro SET cian_id = NULL")
        cleared_count = await conn.fetchval("SELECT COUNT(*) FROM metro WHERE cian_id IS NULL")
        print(f"‚úÖ –û—á–∏—â–µ–Ω–æ {cleared_count} –∑–Ω–∞—á–µ–Ω–∏–π cian_id")
        return cleared_count
    except Exception as e:
        print(f"[DB] –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ cian_id: {e}")
        return 0

async def update_metro_cian_id(conn: asyncpg.Connection, station_id: int, cian_id: int) -> bool:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç cian_id –¥–ª—è —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ"""
    try:
        result = await conn.execute("""
        UPDATE metro 
        SET cian_id = $1
        WHERE id = $2
        """, cian_id, station_id)
        return True
    except Exception as e:
        print(f"[DB] –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è cian_id –¥–ª—è —Å—Ç–∞–Ω—Ü–∏–∏ {station_id}: {e}")
        return False

async def map_cian_to_metro(conn: asyncpg.Connection) -> Dict:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞–Ω—Ü–∏–π –¶–ò–ê–ù —Å —Ç–∞–±–ª–∏—Ü–µ–π metro"""
    print("\n=== –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –°–¢–ê–ù–¶–ò–ô –ú–ï–¢–†–û ===")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞–Ω—Ü–∏–∏ –∏–∑ CSV
    csv_stations = load_stations_from_csv(STATIONS_CSV_PATH)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(csv_stations)} —Å—Ç–∞–Ω—Ü–∏–π –≤ CSV —Ñ–∞–π–ª–µ")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞–Ω—Ü–∏–∏ –∏–∑ –ë–î
    db_stations = await get_metro_stations(conn)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(db_stations)} —Å—Ç–∞–Ω—Ü–∏–π –≤ —Ç–∞–±–ª–∏—Ü–µ metro")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
    exact_matches = 0
    partial_matches = 0
    no_matches = 0
    updated_count = 0
    
    print("\n–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–π:")
    print("-" * 80)
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å—Ç–∞–Ω—Ü–∏—è–º –∏–∑ –ë–î –∏ –∏—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ CSV
    for db_station in db_stations:
        db_name = db_station['name']
        db_id = db_station['id']
        db_line_id = db_station['line_id']
        
        print(f"–ë–î: '{db_name}' (ID: {db_id}, –õ–∏–Ω–∏—è: {db_line_id})")
        
        # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ CSV
        potential_matches = []
        
        for csv_station in csv_stations:
            csv_name = csv_station['station_name']
            csv_station_id = csv_station['station_id']
            csv_line_id = csv_station['line_id']
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            normalized_db = normalize_station_name(db_name)
            normalized_csv = normalize_station_name(csv_name)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            if normalized_db == normalized_csv:
                potential_matches.append({
                    'csv_station': csv_station,
                    'confidence': 1.0,
                    'line_diff': abs(db_line_id - csv_line_id)
                })
        
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–µ–µ
        if potential_matches:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ä–∞–∑–Ω–∏—Ü–µ –≤ line_id
            potential_matches.sort(key=lambda x: (x['confidence'], x['line_diff']))
            
            best_match = potential_matches[0]
            csv_station = best_match['csv_station']
            csv_station_id = csv_station['station_id']
            csv_line_id = csv_station['line_id']
            line_diff = best_match['line_diff']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥—Ä—É–≥–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –±–ª–∏–∑–∫–∏–º–∏ line_id
            close_matches = [m for m in potential_matches if m['line_diff'] <= 5]
            
            if len(close_matches) > 1 and line_diff <= 5:
                print(f"  ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–∞–π–¥–µ–Ω–æ {len(close_matches)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –±–ª–∏–∑–∫–∏–º–∏ line_id:")
                for i, match in enumerate(close_matches[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                    m = match['csv_station']
                    print(f"    {i+1}. –õ–∏–Ω–∏—è {m['line_id']} ({m['line_name']}) - ID: {m['station_id']} (—Ä–∞–∑–Ω–∏—Ü–∞: {match['line_diff']})")
                
                # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ line_id <= 5, —Å–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                if line_diff <= 5:
                    print(f"  ‚ùì –†–∞–∑–Ω–∏—Ü–∞ –≤ line_id: {line_diff} (‚â§ 5). –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ.")
                    print(f"  üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: –õ–∏–Ω–∏—è {csv_line_id} (—Ä–∞–∑–Ω–∏—Ü–∞: {line_diff})")
                    
                    # –í –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ –≤—ã–±–∏—Ä–∞–µ–º —Å –Ω–∞–∏–º–µ–Ω—å—à–µ–π —Ä–∞–∑–Ω–∏—Ü–µ–π –≤ line_id
                    print(f"  ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–æ: –õ–∏–Ω–∏—è {csv_line_id} (—Ä–∞–∑–Ω–∏—Ü–∞: {line_diff})")
                else:
                    print(f"  ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–æ: –õ–∏–Ω–∏—è {csv_line_id} (—Ä–∞–∑–Ω–∏—Ü–∞: {line_diff})")
            else:
                print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: '{csv_station['station_name']}' (–õ–∏–Ω–∏—è: {csv_line_id}, CIAN ID: {csv_station_id})")
            
            exact_matches += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º cian_id –≤ —Ç–∞–±–ª–∏—Ü–µ metro
            if await update_metro_cian_id(conn, db_id, csv_station_id):
                updated_count += 1
                print(f"  ‚úì –û–±–Ω–æ–≤–ª–µ–Ω cian_id = {csv_station_id}")
            else:
                print(f"  ‚úó –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è cian_id")
        
        else:
            # –ï—Å–ª–∏ —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–±—É–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ
            partial_match = None
            best_confidence = 0.0
            
            for csv_station in csv_stations:
                csv_name = csv_station['station_name']
                csv_station_id = csv_station['station_id']
                csv_line_id = csv_station['line_id']
                
                normalized_db = normalize_station_name(db_name)
                normalized_csv = normalize_station_name(csv_name)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if normalized_csv in normalized_db or normalized_db in normalized_csv:
                    confidence = 0.8
                    if confidence > best_confidence:
                        partial_match = csv_station
                        best_confidence = confidence
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤–∞–º
                db_words = set(normalized_db.split())
                csv_words = set(normalized_csv.split())
                
                if db_words and csv_words:
                    intersection = db_words.intersection(csv_words)
                    union = db_words.union(csv_words)
                    if union:
                        jaccard = len(intersection) / len(union)
                        if jaccard > 0.5 and jaccard > best_confidence:
                            partial_match = csv_station
                            best_confidence = jaccard
            
            if partial_match:
                csv_station_id = partial_match['station_id']
                csv_line_id = partial_match['line_id']
                line_diff = abs(db_line_id - csv_line_id)
                
                print(f"  ~ –ß–ê–°–¢–ò–ß–ù–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: '{partial_match['station_name']}' (–õ–∏–Ω–∏—è: {csv_line_id}, CIAN ID: {csv_station_id}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_confidence:.2f})")
                print(f"    –†–∞–∑–Ω–∏—Ü–∞ –≤ line_id: {line_diff}")
                
                partial_matches += 1
                
                # –û–±–Ω–æ–≤–ª—è–µ–º cian_id –≤ —Ç–∞–±–ª–∏—Ü–µ metro
                if await update_metro_cian_id(conn, db_id, csv_station_id):
                    updated_count += 1
                    print(f"  ‚úì –û–±–Ω–æ–≤–ª–µ–Ω cian_id = {csv_station_id}")
                else:
                    print(f"  ‚úó –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è cian_id")
            else:
                print(f"  ‚úó –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ù–ï –ù–ê–ô–î–ï–ù–û")
                no_matches += 1
        
        print()
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("=" * 80)
    print("–ò–¢–û–ì–ò –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø:")
    print(f"–¢–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {exact_matches}")
    print(f"–ß–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {partial_matches}")
    print(f"–ë–µ–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {no_matches}")
    print(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î: {updated_count}")
    
    return {
        'exact_matches': exact_matches,
        'partial_matches': partial_matches,
        'no_matches': no_matches,
        'updated_count': updated_count
    }

async def show_mapping_results(conn: asyncpg.Connection) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
    print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø ===")
    
    try:
        # –°—Ç–∞–Ω—Ü–∏–∏ —Å cian_id
        mapped_stations = await conn.fetch("""
        SELECT line_id, name, cian_id
        FROM metro
        WHERE cian_id IS NOT NULL
        ORDER BY line_id, name
        """)
        
        if mapped_stations:
            print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(mapped_stations)} —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∞–Ω—Ü–∏–π:")
            print("-" * 60)
            for row in mapped_stations:
                print(f"–õ–∏–Ω–∏—è {row['line_id']} | {row['name']} | CIAN: {row['cian_id']}")
        else:
            print("–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∞–Ω—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –°—Ç–∞–Ω—Ü–∏–∏ –±–µ–∑ cian_id
        unmapped_stations = await conn.fetch("""
        SELECT line_id, name
        FROM metro
        WHERE cian_id IS NULL
        ORDER BY line_id, name
        LIMIT 20
        """)
        
        if unmapped_stations:
            print(f"\n–ü–µ—Ä–≤—ã–µ 20 –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç–∞–Ω—Ü–∏–π:")
            print("-" * 60)
            for row in unmapped_stations:
                print(f"–õ–∏–Ω–∏—è {row['line_id']} | {row['name']}")
            
            if len(unmapped_stations) == 20:
                print("... (–ø–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 20)")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π
        confidence_stats = await conn.fetch("""
        SELECT 
            CASE 
                WHEN cian_id IS NOT NULL THEN '–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ'
                ELSE '–ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ'
            END as status,
            COUNT(*) as count
        FROM metro
        GROUP BY status
        ORDER BY status
        """)
        
        if confidence_stats:
            print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:")
            print("-" * 40)
            for row in confidence_stats:
                print(f"{row['status']}: {row['count']} —Å—Ç–∞–Ω—Ü–∏–π")
        
    except Exception as e:
        print(f"[DB] –û—à–∏–±–∫–∞ –ø–æ–∫–∞–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")



async def export_mapping_results(conn: asyncpg.Connection, output_file: str = "metro_mapping_results.csv") -> None:
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤ CSV —Ñ–∞–π–ª"""
    print(f"\n=== –≠–ö–°–ü–û–†–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –í {output_file} ===")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç–∞–Ω—Ü–∏–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        rows = await conn.fetch("""
        SELECT 
            m.line_id,
            m.name,
            m.cian_id,
            CASE 
                WHEN m.cian_id IS NOT NULL THEN '–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ'
                ELSE '–ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ'
            END as mapping_status
        FROM metro m
        ORDER BY m.line_id, m.id
        """)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ CSV
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'line_id', 'name', 'cian_id', 'mapping_status'
            ])
            writer.writeheader()
            
            for row in rows:
                writer.writerow(dict(row))
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {output_file}")
        print(f"–ó–∞–ø–∏—Å–∞–Ω–æ {len(rows)} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")

# ========== –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ==========

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("–°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –°–¢–ê–ù–¶–ò–ô –ú–ï–¢–†–û –¶–ò–ê–ù ‚Üî –ë–î")
    print("=" * 50)
    
    if not DATABASE_URL:
        print("‚ùå –û—à–∏–±–∫–∞: DATABASE_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")
        return
    
    if not os.path.exists(STATIONS_CSV_PATH):
        print(f"‚ö†Ô∏è  –§–∞–π–ª {STATIONS_CSV_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("–°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª stations.csv...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å—Ç–∞–Ω—Ü–∏—è–º–∏
        test_stations = [
            "line_id,line_name,station_id,station_name",
            "4,–ö–∞–ª–∏–Ω–∏–Ω—Å–∫–æ-–°–æ–ª–Ω—Ü–µ–≤—Å–∫–∞—è,1,–ê–≤–∏–∞–º–æ—Ç–æ—Ä–Ω–∞—è",
            "4,–ö–∞–ª–∏–Ω–∏–Ω—Å–∫–æ-–°–æ–ª–Ω—Ü–µ–≤—Å–∫–∞—è,76,–ù–æ–≤–æ–≥–∏—Ä–µ–µ–≤–æ",
            "4,–ö–∞–ª–∏–Ω–∏–Ω—Å–∫–æ-–°–æ–ª–Ω—Ü–µ–≤—Å–∫–∞—è,536,–ü—ã—Ö—Ç–∏–Ω–æ",
            "3,–ó–∞–º–æ—Å–∫–≤–æ—Ä–µ—Ü–∫–∞—è,2,–ê–≤—Ç–æ–∑–∞–≤–æ–¥—Å–∫–∞—è",
            "3,–ó–∞–º–æ—Å–∫–≤–æ—Ä–µ—Ü–∫–∞—è,9,–ê—ç—Ä–æ–ø–æ—Ä—Ç"
        ]
        
        with open(STATIONS_CSV_PATH, 'w', encoding='utf-8') as f:
            f.write('\n'.join(test_stations))
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª {STATIONS_CSV_PATH} —Å {len(test_stations)-1} —Å—Ç–∞–Ω—Ü–∏—è–º–∏")
        print("–î–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–ø—É—Å—Ç–∏—Ç–µ cian_metro.py")
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
    try:
        conn = await asyncpg.connect(DATABASE_URL)
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        return
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É metro –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        await create_metro_table(conn)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ
        count = await conn.fetchval("SELECT COUNT(*) FROM metro")
        if count == 0:
            print("‚ùå –¢–∞–±–ª–∏—Ü–∞ metro –ø—É—Å—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.")
            return
        else:
            print(f"‚úÖ –í —Ç–∞–±–ª–∏—Ü–µ metro —É–∂–µ –µ—Å—Ç—å {count} —Å—Ç–∞–Ω—Ü–∏–π")
        
        # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ cian_id –ø–µ—Ä–µ–¥ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º
        await clear_existing_cian_ids(conn)

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞–Ω—Ü–∏–∏
        mapping_stats = await map_cian_to_metro(conn)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        await show_mapping_results(conn)
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV
        await export_mapping_results(conn)
        
        print(f"\n‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç–∞–Ω—Ü–∏–π: {mapping_stats['exact_matches'] + mapping_stats['partial_matches'] + mapping_stats['no_matches']}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
    finally:
        await conn.close()
        print("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")

if __name__ == '__main__':
    asyncio.run(main())
